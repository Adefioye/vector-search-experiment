{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e5154de6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/vector-search/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: answerdotai/ModernBERT-base\n",
      "Number of parameters: 149.01M\n"
     ]
    }
   ],
   "source": [
    "# Load the model from Hugging Face and compute number of parameters\n",
    "from transformers import AutoModel\n",
    "\n",
    "model_name = \"answerdotai/ModernBERT-base\"\n",
    "\n",
    "model = AutoModel.from_pretrained(model_name)\n",
    "# Divide the number of parameters by 1 million for easier readability\n",
    "def num_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters()) / 1_000_000\n",
    "\n",
    "print(f\"Model: {model_name}\")\n",
    "print(f\"Number of parameters: {num_parameters(model):.2f}M\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a6b5528d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nreimers/TinyBERT_L-4_H-312_v2 were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'fit_denses.0.bias', 'fit_denses.0.weight', 'fit_denses.1.bias', 'fit_denses.1.weight', 'fit_denses.2.bias', 'fit_denses.2.weight', 'fit_denses.3.bias', 'fit_denses.3.weight', 'fit_denses.4.bias', 'fit_denses.4.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: nreimers/TinyBERT_L-4_H-312_v2\n",
      "Number of parameters: 14.35M\n"
     ]
    }
   ],
   "source": [
    "model_name = \"nreimers/TinyBERT_L-4_H-312_v2\"\n",
    "\n",
    "model = AutoModel.from_pretrained(model_name)\n",
    "\n",
    "print(f\"Model: {model_name}\")\n",
    "print(f\"Number of parameters: {num_parameters(model):.2f}M\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61e2eb05",
   "metadata": {},
   "source": [
    "## Evaluate on NanoBEIR datasets on sentence transformers library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "675c494a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No sentence-transformers model found with name pinecone/ConstBERT. Creating a new one with mean pooling.\n",
      "                                                                        \r"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "from sentence_transformers.evaluation import NanoBEIREvaluator\n",
    "\n",
    "# model = SentenceTransformer('answerdotai/ModernBERT-base')\n",
    "model = SentenceTransformer('pinecone/ConstBERT')\n",
    "\n",
    "# dataset_name_to_human_readable = {\n",
    "#     \"climatefever\": \"ClimateFEVER\",\n",
    "#     \"dbpedia\": \"DBPedia\",\n",
    "#     \"fever\": \"FEVER\",\n",
    "#     \"fiqa2018\": \"FiQA2018\",\n",
    "#     \"hotpotqa\": \"HotpotQA\",\n",
    "#     \"msmarco\": \"MSMARCO\",\n",
    "#     \"nfcorpus\": \"NFCorpus\",\n",
    "#     \"nq\": \"NQ\",\n",
    "#     \"quoraretrieval\": \"QuoraRetrieval\",\n",
    "#     \"scidocs\": \"SCIDOCS\",\n",
    "#     \"arguana\": \"ArguAna\",\n",
    "#     \"scifact\": \"SciFact\",\n",
    "#     \"touche2020\": \"Touche2020\",\n",
    "# }\n",
    "\n",
    "datasets = [\"QuoraRetrieval\", \"MSMARCO\"]\n",
    "query_prompts = {\n",
    "    \"QuoraRetrieval\": \"Instruct: Given a question, retrieve questions that are semantically equivalent to the given question\\\\nQuery: \",\n",
    "    \"Touche2020\": \"Instruct: Given a question, retrieve questions that are semantically equivalent to the given question\\\\nQuery: \",\n",
    "    \"NFCorpus\": \"Instruct: Given a question, retrieve questions that are semantically equivalent to the given question\\\\nQuery: \",\n",
    "    \"SciFact\": \"Instruct: Given a question, retrieve questions that are semantically equivalent to the given question\\\\nQuery: \",\n",
    "    \"ArguAna\": \"Instruct: Given a question, retrieve questions that are semantically equivalent to the given question\\\\nQuery: \",\n",
    "    \"SCIDOCS\": \"Instruct: Given a question, retrieve questions that are semantically equivalent to the given question\\\\nQuery: \",\n",
    "    \"FiQA2018\": \"Instruct: Given a question, retrieve questions that are semantically equivalent to the given question\\\\nQuery: \",\n",
    "    \"MSMARCO\": \"Instruct: Given a web search query, retrieve relevant passages that answer the query\\\\nQuery: \"\n",
    "    }\n",
    "\n",
    "evaluator = NanoBEIREvaluator(\n",
    "    dataset_names=datasets,\n",
    "    query_prompts=query_prompts,\n",
    "    )\n",
    "\n",
    "results = evaluator(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1e17b39",
   "metadata": {},
   "source": [
    "## Document results\n",
    "\n",
    "Mean NDCG@10\n",
    "- joe32140/ModernBERT-base-msmarco' (0.62)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ae0e738c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<All keys matched successfully>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: nomic-ai/nomic-embed-text-v1-unsupervised\n",
      "Number of parameters: 136.73M\n"
     ]
    }
   ],
   "source": [
    "# Load the model from Hugging Face and compute number of parameters\n",
    "from transformers import AutoModel\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "model_name = \"nomic-ai/nomic-embed-text-v1-unsupervised\"\n",
    "\n",
    "model = AutoModel.from_pretrained(model_name, trust_remote_code=True)\n",
    "# model = SentenceTransformer(model, trust_remote_code=True)\n",
    "# Divide the number of parameters by 1 million for easier readability\n",
    "def num_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters()) / 1_000_000\n",
    "\n",
    "print(f\"Model: {model_name}\")\n",
    "print(f\"Number of parameters: {num_parameters(model):.2f}M\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65dc8939",
   "metadata": {},
   "source": [
    "## Number of parameters for embedding models\n",
    "\n",
    "- nomic-ai/modernbert-embed-base (149.01M)\n",
    "- nomic-ai/modernbert-embed-base-unsupervised (149.01M)\n",
    "- nomic-ai/nomic-embed-text-v1-unsupervised ((136.73M))\n",
    "- nomic-ai/nomic-embed-text-v1 (136.73M)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e453e8ac",
   "metadata": {},
   "source": [
    "## Number of parameters for some models\n",
    "\n",
    "- kokolamba/ConstBERT-DPR-8e-05-CMNRL-minibs128 (109.48M)\n",
    "- kokolamba/ModernBERT-base-DPR-8e-05-CMNRL-minibs16 (149.01M)\n",
    "- kokolamba/ModernBERT-base-DPR-8e-05-CMNRL-minibs128 (149.01M)\n",
    "- kokolamba/ModernBERT-large-DPR-8e-05-CMNRL-minibs64 (394.78M)\n",
    "- answerdotai/ModernBERT-base (149.01M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d434091a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'docid': '4983',\n",
       " 'text': 'Alterations of the architecture of cerebral white matter in the developing human brain can affect cortical development and result in functional disabilities. A line scan diffusion-weighted magnetic resonance imaging (MRI) sequence with diffusion tensor analysis was applied to measure the apparent diffusion coefficient, to calculate relative anisotropy, and to delineate three-dimensional fiber architecture in cerebral white matter in preterm (n = 17) and full-term infants (n = 7). To assess effects of prematurity on cerebral white matter development, early gestation preterm infants (n = 10) were studied a second time at term. In the central white matter the mean apparent diffusion coefficient at 28 wk was high, 1.8 microm2/ms, and decreased toward term to 1.2 microm2/ms. In the posterior limb of the internal capsule, the mean apparent diffusion coefficients at both times were similar (1.2 versus 1.1 microm2/ms). Relative anisotropy was higher the closer birth was to term with greater absolute values in the internal capsule than in the central white matter. Preterm infants at term showed higher mean diffusion coefficients in the central white matter (1.4 +/- 0.24 versus 1.15 +/- 0.09 microm2/ms, p = 0.016) and lower relative anisotropy in both areas compared with full-term infants (white matter, 10.9 +/- 0.6 versus 22.9 +/- 3.0%, p = 0.001; internal capsule, 24.0 +/- 4.44 versus 33.1 +/- 0.6% p = 0.006). Nonmyelinated fibers in the corpus callosum were visible by diffusion tensor MRI as early as 28 wk; full-term and preterm infants at term showed marked differences in white matter fiber organization. The data indicate that quantitative assessment of water diffusion by diffusion tensor MRI provides insight into microstructural development in cerebral white matter in living infants.'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "passages[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e5bece95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.10.18\n"
     ]
    }
   ],
   "source": [
    "!python --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "157790b0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (vector-search)",
   "language": "python",
   "name": "vector-search"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
